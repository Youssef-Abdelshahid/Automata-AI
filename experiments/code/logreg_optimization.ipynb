{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed95a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570efcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = data.data.astype(np.float32, copy=False)\n",
    "y = data.target.astype(np.int32, copy=False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_test:\", X_test.shape)\n",
    "print(\"Classes:\", np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70216dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = r\"logreg_model_before_optimization.joblib\"\n",
    "\n",
    "def _is_fitted_logreg(m):\n",
    "    return hasattr(m, \"coef_\") and hasattr(m, \"intercept_\") and hasattr(m, \"classes_\")\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    obj = joblib.load(MODEL_PATH)\n",
    "\n",
    "    if not isinstance(obj, LogisticRegression):\n",
    "        raise TypeError(f\"Loaded object is not LogisticRegression. Type={type(obj)}\")\n",
    "\n",
    "    if not _is_fitted_logreg(obj):\n",
    "        raise ValueError(\"Loaded LogisticRegression is not fitted (missing coef_/intercept_/classes_).\")\n",
    "\n",
    "    model = obj\n",
    "    print(\"Loaded LogisticRegression from:\", MODEL_PATH)\n",
    "\n",
    "else:\n",
    "    model = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        C=1.0,\n",
    "        solver=\"lbfgs\",\n",
    "        max_iter=2000,\n",
    "        n_jobs=None\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Trained baseline LogisticRegression (because file not found).\")\n",
    "\n",
    "print(\"Model ready. Fitted:\", _is_fitted_logreg(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc732ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_joblib(m, path: str) -> float:\n",
    "    joblib.dump(m, path)\n",
    "    return os.path.getsize(path) / (1024 * 1024)\n",
    "\n",
    "p = model.predict_proba(X_test)[:, 1]\n",
    "y_hat = (p >= 0.5).astype(np.int32)\n",
    "acc = float(accuracy_score(y_test, y_hat))\n",
    "\n",
    "base_path = \"logreg_baseline.joblib\"\n",
    "base_mb = export_joblib(model, base_path)\n",
    "\n",
    "print(\"Baseline accuracy:\", acc)\n",
    "print(\"Baseline exported:\", base_path, f\"({base_mb:.6f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be05ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRUNE_ABS_WEIGHT_BELOW = 1e-4 \n",
    "\n",
    "optimized_model = deepcopy(model)\n",
    "\n",
    "optimized_model.coef_ = optimized_model.coef_.astype(np.float32, copy=False)\n",
    "optimized_model.intercept_ = optimized_model.intercept_.astype(np.float32, copy=False)\n",
    "\n",
    "if PRUNE_ABS_WEIGHT_BELOW > 0:\n",
    "    w = optimized_model.coef_\n",
    "    mask = np.abs(w) < PRUNE_ABS_WEIGHT_BELOW\n",
    "    w = w.copy()\n",
    "    w[mask] = 0.0\n",
    "    optimized_model.coef_ = w\n",
    "\n",
    "print(\"Optimization done.\")\n",
    "print(\"Prune threshold:\", PRUNE_ABS_WEIGHT_BELOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f90f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt = optimized_model.predict_proba(X_test)[:, 1]\n",
    "y_hat_opt = (p_opt >= 0.5).astype(np.int32)\n",
    "acc_opt = float(accuracy_score(y_test, y_hat_opt))\n",
    "\n",
    "opt_path = \"logreg_optimized.joblib\"\n",
    "opt_mb = export_joblib(optimized_model, opt_path)\n",
    "\n",
    "loaded = joblib.load(opt_path)\n",
    "if not isinstance(loaded, LogisticRegression) or not _is_fitted_logreg(loaded):\n",
    "    raise ValueError(\"Reload failed or loaded model is not a fitted LogisticRegression.\")\n",
    "\n",
    "p_loaded = loaded.predict_proba(X_test)[:, 1]\n",
    "max_diff = float(np.max(np.abs(p_loaded - p_opt)))\n",
    "\n",
    "print(\"Optimized accuracy:\", acc_opt)\n",
    "print(\"Optimized exported:\", opt_path, f\"({opt_mb:.6f} MB)\")\n",
    "print(\"Reload max |diff|:\", max_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53148c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def measure_inference_ms_logreg(\n",
    "    m: LogisticRegression,\n",
    "    X: np.ndarray,\n",
    "    batch_size: int = 1,\n",
    "    n_warmup: int = 50,\n",
    "    n_runs: int = 500,\n",
    ") -> dict:\n",
    "    if not _is_fitted_logreg(m):\n",
    "        raise ValueError(\"Model is not fitted.\")\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    n = X.shape[0]\n",
    "    if n == 0:\n",
    "        raise ValueError(\"X is empty.\")\n",
    "    if batch_size <= 0:\n",
    "        raise ValueError(\"batch_size must be >= 1.\")\n",
    "\n",
    "    starts = [((i * batch_size) % n) for i in range(max(n_warmup, n_runs))]\n",
    "    batches = [X[s:s+batch_size] for s in starts]\n",
    "\n",
    "    for xb in batches[:n_warmup]:\n",
    "        _ = m.predict_proba(xb)\n",
    "\n",
    "    t_sklearn = []\n",
    "    for xb in batches[:n_runs]:\n",
    "        t0 = time.perf_counter()\n",
    "        _ = m.predict_proba(xb)\n",
    "        t1 = time.perf_counter()\n",
    "        t_sklearn.append((t1 - t0) * 1000.0)\n",
    "\n",
    "    t_sklearn = np.asarray(t_sklearn, dtype=np.float64)\n",
    "\n",
    "    w = m.coef_.astype(np.float32, copy=False)\n",
    "    b = m.intercept_.astype(np.float32, copy=False)\n",
    "\n",
    "    for xb in batches[:n_warmup]:\n",
    "        z = xb @ w.T + b\n",
    "        _ = _sigmoid(z)\n",
    "\n",
    "    t_numpy = []\n",
    "    for xb in batches[:n_runs]:\n",
    "        t0 = time.perf_counter()\n",
    "        z = xb @ w.T + b\n",
    "        _ = _sigmoid(z)\n",
    "        t1 = time.perf_counter()\n",
    "        t_numpy.append((t1 - t0) * 1000.0)\n",
    "\n",
    "    t_numpy = np.asarray(t_numpy, dtype=np.float64)\n",
    "\n",
    "    def pack(arr):\n",
    "        return {\n",
    "            \"mean_ms_per_batch\": float(arr.mean()),\n",
    "            \"p50_ms_per_batch\": float(np.percentile(arr, 50)),\n",
    "            \"p95_ms_per_batch\": float(np.percentile(arr, 95)),\n",
    "        }\n",
    "\n",
    "    sk = pack(t_sklearn)\n",
    "    npk = pack(t_numpy)\n",
    "\n",
    "    return {\n",
    "        \"batch_size\": int(batch_size),\n",
    "        \"sklearn\": {\n",
    "            **sk,\n",
    "            \"mean_ms_per_sample\": sk[\"mean_ms_per_batch\"] / batch_size,\n",
    "            \"p50_ms_per_sample\": sk[\"p50_ms_per_batch\"] / batch_size,\n",
    "            \"p95_ms_per_sample\": sk[\"p95_ms_per_batch\"] / batch_size,\n",
    "        },\n",
    "        \"numpy\": {\n",
    "            **npk,\n",
    "            \"mean_ms_per_sample\": npk[\"mean_ms_per_batch\"] / batch_size,\n",
    "            \"p50_ms_per_sample\": npk[\"p50_ms_per_batch\"] / batch_size,\n",
    "            \"p95_ms_per_sample\": npk[\"p95_ms_per_batch\"] / batch_size,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [1, 8, 32, 128]\n",
    "results = []\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    rb = measure_inference_ms_logreg(model, X_test, batch_size=bs)\n",
    "    rb[\"model\"] = \"baseline\"\n",
    "    results.append(rb)\n",
    "\n",
    "    ro = measure_inference_ms_logreg(optimized_model, X_test, batch_size=bs)\n",
    "    ro[\"model\"] = \"optimized\"\n",
    "    results.append(ro)\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    b = next(r for r in results if r[\"model\"] == \"baseline\" and r[\"batch_size\"] == bs)\n",
    "    o = next(r for r in results if r[\"model\"] == \"optimized\" and r[\"batch_size\"] == bs)\n",
    "\n",
    "    print(f\"\\nBatch size = {bs}\")\n",
    "    print(f\"  Baseline  sklearn: mean {b['sklearn']['mean_ms_per_batch']:.4f} ms/batch | {b['sklearn']['mean_ms_per_sample']:.4f} ms/sample\")\n",
    "    print(f\"  Optimized sklearn: mean {o['sklearn']['mean_ms_per_batch']:.4f} ms/batch | {o['sklearn']['mean_ms_per_sample']:.4f} ms/sample\")\n",
    "\n",
    "    print(f\"  Baseline  numpy  : mean {b['numpy']['mean_ms_per_batch']:.4f} ms/batch | {b['numpy']['mean_ms_per_sample']:.4f} ms/sample\")\n",
    "    print(f\"  Optimized numpy  : mean {o['numpy']['mean_ms_per_batch']:.4f} ms/batch | {o['numpy']['mean_ms_per_sample']:.4f} ms/sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def measure_inference_time_logistic(\n",
    "    model: LogisticRegression,\n",
    "    X: np.ndarray,\n",
    "    num_runs: int = 100,\n",
    "    warm_up: int = 10,\n",
    "    use_proba: bool = True\n",
    "):\n",
    "    if not isinstance(model, LogisticRegression):\n",
    "        raise TypeError(f\"model must be sklearn.linear_model.LogisticRegression, got: {type(model)}\")\n",
    "\n",
    "    if not (hasattr(model, \"coef_\") and hasattr(model, \"intercept_\") and hasattr(model, \"classes_\")):\n",
    "        raise ValueError(\"LogisticRegression model is not fitted (missing coef_/intercept_/classes_).\")\n",
    "\n",
    "    X = np.asarray(X, dtype=np.float32)\n",
    "    if X.ndim != 2:\n",
    "        raise ValueError(f\"X must be 2D array [n_samples, n_features], got shape: {X.shape}\")\n",
    "    if X.shape[0] == 0:\n",
    "        raise ValueError(\"X has 0 rows.\")\n",
    "\n",
    "    if num_runs <= 0:\n",
    "        raise ValueError(\"num_runs must be >= 1.\")\n",
    "    if warm_up < 0:\n",
    "        raise ValueError(\"warm_up must be >= 0.\")\n",
    "\n",
    "    if use_proba:\n",
    "        if not hasattr(model, \"predict_proba\"):\n",
    "            raise AttributeError(\"model has no predict_proba(). Set use_proba=False.\")\n",
    "        infer = model.predict_proba\n",
    "    else:\n",
    "        infer = model.predict\n",
    "\n",
    "    for _ in range(warm_up):\n",
    "        _ = infer(X)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(num_runs):\n",
    "        _ = infer(X)\n",
    "    end = time.perf_counter()\n",
    "\n",
    "    total_time_sec = end - start\n",
    "    avg_time_per_run_sec = total_time_sec / num_runs\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    avg_time_per_sample_us = (avg_time_per_run_sec / num_samples) * 1e6\n",
    "    total_avg_time_ms = avg_time_per_run_sec * 1000\n",
    "\n",
    "    print(f\"--- Inference Speed ({num_runs} runs) ---\")\n",
    "    print(f\"Total time per batch: {total_avg_time_ms:.4f} ms\")\n",
    "    print(f\"Time per sample:      {avg_time_per_sample_us:.4f} Âµs\")\n",
    "\n",
    "    return {\n",
    "        \"time_per_sample_us\": float(avg_time_per_sample_us),\n",
    "        \"total_time_ms\": float(total_avg_time_ms),\n",
    "        \"num_samples\": int(num_samples),\n",
    "        \"use_proba\": bool(use_proba),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e230de09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline LogisticRegression:\")\n",
    "_ = measure_inference_time_logistic(model, X_test)\n",
    "\n",
    "print(\"\\nOptimized LogisticRegression:\")\n",
    "_ = measure_inference_time_logistic(optimized_model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71bd0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_logreg_to_h(m: LogisticRegression, out_path: str) -> bool:\n",
    "    try:\n",
    "        import m2cgen as m2c\n",
    "        import re\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] m2cgen not available:\", e)\n",
    "        return False\n",
    "\n",
    "    if not _is_fitted_logreg(m):\n",
    "        raise ValueError(\"Model is not fitted.\")\n",
    "\n",
    "    try:\n",
    "        c_code = m2c.export_to_c(m)\n",
    "\n",
    "        c_code = re.sub(\n",
    "            r\"memcpy\\(([^,]+),\\s*\\((?:double|float)\\[\\]\\)\\{([^}]+)\\},\\s*(\\d+)\\s*\\*\\s*sizeof\\((double|float)\\)\\);\",\n",
    "            r\"{ \\4 tmp[] = {\\2}; memcpy(\\1, tmp, \\3 * sizeof(\\4)); }\",\n",
    "            c_code\n",
    "        )\n",
    "\n",
    "        stem = os.path.splitext(os.path.basename(out_path))[0]\n",
    "        header_guard = stem.upper() + \"_H\"\n",
    "\n",
    "        wrapped = (\n",
    "            f\"#ifndef {header_guard}\\n#define {header_guard}\\n\\n\"\n",
    "            f\"{c_code}\\n\\n\"\n",
    "            f\"#endif // {header_guard}\\n\"\n",
    "        )\n",
    "\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(wrapped)\n",
    "\n",
    "        print(\"[INFO] Exported header:\", out_path)\n",
    "        print(f\"[HINT] Include using: #include \\\"{os.path.basename(out_path)}\\\"\")\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Header export failed:\", e)\n",
    "        return False\n",
    "\n",
    "export_logreg_to_h(optimized_model, \"logreg_optimized.h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coef_stats(m: LogisticRegression):\n",
    "    w = np.asarray(m.coef_)\n",
    "    total = w.size\n",
    "    nonzero = int(np.count_nonzero(w))\n",
    "    zero = total - nonzero\n",
    "    return {\n",
    "        \"total_weights\": int(total),\n",
    "        \"nonzero_weights\": int(nonzero),\n",
    "        \"zero_weights\": int(zero),\n",
    "        \"sparsity_%\": float(100.0 * zero / total) if total else 0.0\n",
    "    }\n",
    "\n",
    "print(\"Baseline stats :\", coef_stats(model))\n",
    "print(\"Optimized stats:\", coef_stats(optimized_model))\n",
    "\n",
    "if os.path.exists(\"logreg_baseline.joblib\") and os.path.exists(\"logreg_optimized.joblib\"):\n",
    "    b = os.path.getsize(\"logreg_baseline.joblib\") / (1024 * 1024)\n",
    "    o = os.path.getsize(\"logreg_optimized.joblib\") / (1024 * 1024)\n",
    "    print(f\"File size baseline : {b:.6f} MB\")\n",
    "    print(f\"File size optimized: {o:.6f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_overfitting(model, X_train, y_train, X_test, y_test, name=\"model\"):\n",
    "    p_train = model.predict_proba(X_train)[:, 1]\n",
    "    p_test  = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    acc_train = accuracy_score(y_train, (p_train >= 0.5).astype(int))\n",
    "    acc_test  = accuracy_score(y_test,  (p_test  >= 0.5).astype(int))\n",
    "\n",
    "    gap = acc_train - acc_test\n",
    "\n",
    "    print(f\"[{name}] Train acc: {acc_train:.4f}\")\n",
    "    print(f\"[{name}] Test  acc: {acc_test:.4f}\")\n",
    "    print(f\"[{name}] Gap       : {gap:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"train_acc\": float(acc_train),\n",
    "        \"test_acc\": float(acc_test),\n",
    "        \"gap\": float(gap)\n",
    "    }\n",
    "\n",
    "print(\"Baseline:\")\n",
    "_ = evaluate_overfitting(model, X_train, y_train, X_test, y_test, name=\"baseline\")\n",
    "\n",
    "print(\"\\nOptimized:\")\n",
    "_ = evaluate_overfitting(optimized_model, X_train, y_train, X_test, y_test, name=\"optimized\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
